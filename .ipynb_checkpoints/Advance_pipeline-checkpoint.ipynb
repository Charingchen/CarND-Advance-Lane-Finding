{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance Pipeline Land Detection\n",
    "In the Previous project, Canny edge detection and Hough Transformation have limitations on handling shadows, and the constant threshold would not play well with a constantly changing driving environment. A more robust image process logic is require to get a good lane detecting result\n",
    "\n",
    "## Road Map to a More Robust Lane Finding Algorithms \n",
    "The approach would be shown in the following steps\n",
    "1. Camera Calibration and Distortion Correction\n",
    "2. Color and Gradient Threshold Filter\n",
    "3. Perspective Transform Calculation\n",
    "4. Sliding Window Lane Line Finding\n",
    "5. Curvature Measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#glob is used to reading all the similar calbration image\n",
    "import glob\n",
    "# import all cal images\n",
    "cal_images = glob.glob ('camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "This Camera Calibration only run once. The Camera matrix is save as a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all images\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "# Obj points should not change and only based on the chesss board format\n",
    "# Preparing object points, like (0,0,0), (1,0,0) ...\n",
    "objp = np.zeros((6*9,3),np.float32)\n",
    " \n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # Creating x y coordinates\n",
    "\n",
    "for fname in cal_images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    # Convert to gray scale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find Chesse board corners\n",
    "    ret, corners = cv2.findChessboardCorners (gray, (9,6),None)\n",
    "    \n",
    "    if ret:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        \n",
    "# Get the Camera matrix \n",
    "ret,mtx,dist,rvecs,tvecs = cv2.calibrateCamera(objpoints,imgpoints,\n",
    "                                               img.shape[1:],None,None)\n",
    "\n",
    "# Function use to undistort images\n",
    "def undistort_img (img,mtx=mtx,dist=dist):\n",
    "    return cv2.undistort(img,mtx,dist,None,mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color and Gradient Threshold Filter\n",
    "This part of the code is transfered from [parameter_tunning.ipynb](parameter_tunning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(gray, orient='x', thresh=(0, 255)):\n",
    "    \n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "        \n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def mag_threshold(gray, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    abs_arctan = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(abs_arctan)\n",
    "    binary_output[(abs_arctan >= thresh[0]) & (abs_arctan <= thresh[1])] = 1\n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def sobel_gradient (image, overdrive = True, ksize = 3,abs_thresh = (25,200),\n",
    "                    mag_thresh = (40,150),dir_thresh = (0.7,1.3)):\n",
    "    \n",
    "    # Convert to gray scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply each of the thresholding functions according to the compliexity\n",
    "    gradx = abs_sobel_thresh(gray, orient='x', thresh=abs_thresh)\n",
    "    grady = abs_sobel_thresh(gray, orient='y', thresh=abs_thresh)\n",
    "    combined = np.zeros_like(grady)\n",
    "    \n",
    "    # Choose complexity True means more complicated calculation\n",
    "    # If min complexity require only execute x and y gradient\n",
    "    if overdrive: \n",
    "        mag_binary = mag_threshold(gray,sobel_kernel=ksize,thresh= mag_thresh)\n",
    "        dir_binary = dir_threshold(gray, sobel_kernel=ksize, thresh=dir_thresh)\n",
    "        combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    else:\n",
    "        combined[(gradx == 1) & (grady == 1)] = 1       \n",
    "        \n",
    "    return combined\n",
    "# A function only process h and s channels\n",
    "def convert_to_hs (image, thresh_h = [18,100], thresh_s = [90,255]):\n",
    "    \n",
    "    # First convert image to HLS and only take H and S\n",
    "    hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    S = hls[:,:,2]\n",
    "    # Create Binary arrays\n",
    "    binary_h = np.zeros_like(H)\n",
    "    binary_s = np.zeros_like(S)\n",
    "    \n",
    "    binary_h[(H > thresh_h[0]) & (H <= thresh_h[1])] = 1\n",
    "    binary_s[(S >thresh_s[0]) & (S<= thresh_s[1])] = 1\n",
    "    \n",
    "    return binary_h, binary_s\n",
    "    \n",
    "\"\"\"\n",
    "Image process takes a frame iamge and return a binary image as an input of pipeline logic\n",
    "Input: \n",
    "    image: a RGB image array \n",
    "    overdrive: boolean True mean complicated computing include all threshold methods, \n",
    "               False means simple computing only S threshold and xy graidents\n",
    "Return:\n",
    "    combined_binary: all the threhold binary combined\n",
    "    color_binary: used to visuallize the two combines binary. Debugging use only\n",
    "\"\"\"\n",
    "def image_process (image, overdrive = False):\n",
    "    # Fine tune all the threshold here\n",
    "    thresh_h = [23,100]\n",
    "    thresh_s = [170,255]\n",
    "    thresh_r = [220,255]\n",
    "    abs_thresh = (50,200)\n",
    "    mag_thresh = (60,150)\n",
    "\n",
    "    # Get binary H and S from hls color space\n",
    "    binary_h, binary_s = convert_to_hs(image,thresh_h = thresh_h, thresh_s = thresh_s)\n",
    "    combined_binary = np.zeros_like(binary_s)\n",
    "    \n",
    "    if overdrive:\n",
    "        # Grab gradient result \n",
    "        gradient_binary = sobel_gradient(image,ksize=15,\n",
    "                                         abs_thresh=abs_thresh,mag_thresh = mag_thresh)\n",
    "        \n",
    "        # Implement R threhold\n",
    "        R =image[:,:,0]\n",
    "        \n",
    "        binary_r = np.zeros_like(R)\n",
    "        binary_r[(R > thresh_r[0]) & (R <= thresh_r[1])] = 1\n",
    "        \n",
    "        # Combine R with H and S threshold binary\n",
    "        color_thresh_binary = np.zeros_like(binary_s)\n",
    "        color_thresh_binary[((binary_h == 1) & (binary_s ==1))|(binary_r ==1)] = 1\n",
    "        \n",
    "        # Create color binary to visualiize the logic combining\n",
    "        color_binary = np.dstack((binary_r,color_thresh_binary,gradient_binary))*255\n",
    "        # Combine all the binary\n",
    "        combined_binary[(color_thresh_binary ==1)|(gradient_binary ==1)] = 1\n",
    "    \n",
    "    else:\n",
    "        # Grab gradient result \n",
    "        gradient_binary = sobel_gradient(image,overdrive=overdrive,abs_thresh=abs_thresh)\n",
    "        combined_binary[(binary_s ==1)|(gradient_binary ==1)] =1\n",
    "        color_binary = np.dstack((np.zeros_like(gradient_binary),binary_s,gradient_binary))*255\n",
    "    \n",
    "    return combined_binary,color_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform Calculation\n",
    "Now let's define trapezoid mask and preform perspective transform to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mask parameters. This function will adjust src and dst coordinates to different \n",
    "# size of images\n",
    "\n",
    "# mask top width is the top width of the trapezoid\n",
    "# x_offset is the offset on the bottom line X cooridate of the trapezoid\n",
    "# y_offset is the offset on the bottom line Y cooridtate of the trapzoid\n",
    "# dst_offset is the destination rectangle X offset \n",
    "def mask_image (img,mask_top_width = 145, x_offset = 20, y_offset=40, dst_offset = 200):\n",
    "\n",
    "    imshape=img.shape\n",
    "    # Calculate mask height\n",
    "    img_y_mid = imshape[0]*0.5\n",
    "    mask_height = int(img_y_mid*1.25)\n",
    "    img_x_mid = int(imshape[1]*0.5)\n",
    "    top_left = [img_x_mid - mask_top_width*0.5 , mask_height]\n",
    "    top_right = [img_x_mid + mask_top_width*0.5 , mask_height]\n",
    "    bottom_left = [x_offset,imshape[0]-y_offset]\n",
    "    bottom_right = [imshape[1]-x_offset,imshape[0]-y_offset]\n",
    "\n",
    "    # Define the source points\n",
    "    src = np.float32([bottom_left,top_left,top_right,bottom_right])\n",
    "    # Define destination points\n",
    "    # 25 is hardcoded to move the lane line to the bottom of the image\n",
    "    dst = np.float32([[dst_offset, imshape[0]-y_offset+25], [dst_offset, y_offset], \n",
    "                                     [imshape[1]-dst_offset, y_offset], \n",
    "                                     [imshape[1]-dst_offset, imshape[0]-y_offset+25]])\n",
    "    return src, dst\n",
    "\n",
    "\n",
    "\n",
    "def perspective_transform (undist,inverse = False,debug = False):\n",
    "    src,dst = mask_image(undist)\n",
    "    if inverse == False:\n",
    "        M = cv2.getPerspectiveTransform(src,dst)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(dst,src)\n",
    "        \n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "    warped = cv2.warpPerspective(undist,M,img_size)\n",
    "    \n",
    "    if debug:\n",
    "        return warped,src,dst\n",
    "    else:\n",
    "        return warped\n",
    "\n",
    "# Test using straight lines1 \n",
    "straight_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "undist = cv2.undistort(straight_img,mtx,dist,None,mtx)\n",
    "warped,src,dst = perspective_transform(undist,debug =True)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "# prepare src point for scatter plot\n",
    "x1=[]\n",
    "y1=[]\n",
    "for i in src:\n",
    "    x1.append(i[0])\n",
    "    y1.append(i[1])\n",
    "ax1.scatter(x1,y1,color='r')\n",
    "\n",
    "ax1.imshow(undist)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "x2=[]\n",
    "y2=[]\n",
    "for i in dst:\n",
    "    x2.append(i[0])\n",
    "    y2.append(i[1])\n",
    "print(src,'\\n\\n',dst)\n",
    "ax2.scatter(x2,y2,color='r')\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tunning with the test images, I am going to use ` mask_top_width = 155, x_offset = 20, y_offset=40, dst_offset = 200` to get the src and dst coordinates for my Perspective Transform.\n",
    "## Sliding Window Lane Finding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_wrap_img (img, debug == False):\n",
    "    undist= cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    \n",
    "    src,dst = mask_image(undist)\n",
    "    \n",
    "    binary,color_binary = image_process(undist)\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "#     warped = perspective_transform(binary,img_size,src,dst)\n",
    "    warped = perspective_transform(binary)\n",
    "    if debug:                              \n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(binary)\n",
    "        ax1.set_title('Binary Image', fontsize=50)\n",
    "        ax2.imshow(warped)\n",
    "        ax2.set_title('Warped Image', fontsize=50)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        \n",
    "    return warped\n",
    "\n",
    "\n",
    "binary_wrap = binary_wrap_img(straight_img,debug =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        # Find the four below boundaries of the window #\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        #Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_in\n",
    "        ds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "    \n",
    "        #If found > minpix pixels, recenter next window \n",
    "        #(`right` or `leftx_current`) on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "        \n",
    "    left_lane_inds = ((nonzerox >= (left_fit[0]*nonzeroy**2+left_fit[1]*nonzeroy+\n",
    "                        left_fit[2] - margin)) & \n",
    "                        (nonzerox < (left_fit[0]*nonzeroy**2+left_fit[1]*nonzeroy+\n",
    "                        left_fit[2] + margin))).nonzero()[0]\n",
    "    right_lane_inds = ((nonzerox >= (right_fit[0]*nonzeroy**2+right_fit[1]*nonzeroy+\n",
    "                        right_fit[2] - margin)) & \n",
    "                        (nonzerox < (right_fit[0]*nonzeroy**2+right_fit[1]*nonzeroy+\n",
    "                        right_fit[2] + margin))).nonzero()[0]\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    print(left_fit,right_fit)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\"\"\"\n",
    "Logic to handle video processing frame by frame find lan pixel\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def fit_lane_line (binary_wrap, prev_left_fit,prev_right_fit):\n",
    "    \n",
    "    #Detect if there is previous line fit\n",
    "    \n",
    "    if prev_left_fit == [] and prev_right_fit==[]:\n",
    "        # call find lane line for the first time\n",
    "        #  if debug is true, Visuallize using sliding windows\n",
    "    else:\n",
    "        # call search around poly instead\n",
    "        # search around poly has handle there is no find according to prevous logic to catch \n",
    "        # search find failure\n",
    "        \n",
    "        # if debug is true, Visualize using ploy fill\n",
    "    \n",
    "    # return left fit x right fitx and polty for curvature caculation\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time output = fit_polynomial(binary_wrap)\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
